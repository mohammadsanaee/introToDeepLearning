{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadsanaee/introToDeepLearning/blob/main/1_Dependency_Reconstruction_TASK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZJ032IKCYY2"
      },
      "source": [
        "# Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93ukQuerCYY4"
      },
      "source": [
        "In this notebook we will be working on toy problem of reconstructing the hidden \n",
        "dependency. We will work with synthetic dataset. As a basic example, we will\n",
        "start with data\n",
        "\n",
        "$$f(x) = \\sin(x) + \\epsilon,$$\n",
        "\n",
        "where $\\epsilon$ is random noise that will simulate measurement inaccuracies.\n",
        "\n",
        "Our task will be to prepare the network $Net(x)$ that will accept single value $x$\n",
        "as an argument and yield single value $y$ as a forecast.\n",
        "\n",
        "Ideally the network should be as close to the hidden dependency as possible:\n",
        "\n",
        "$$Net(x) \\rightarrow \\sin(x)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxwD5OaVCYY5"
      },
      "source": [
        "# Generating the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akbypZWgCYY5"
      },
      "source": [
        "First we will generate the clean samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfdZdAxJCYY6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.rcParams['figure.figsize'] = (10.0, 5.0)\n",
        "\n",
        "x_train = torch.rand(100)\n",
        "x_train = x_train * 20.0 - 10.0\n",
        "\n",
        "y_train = torch.sin(x_train)\n",
        "\n",
        "plt.plot(x_train.numpy(), y_train.numpy(), 'o')\n",
        "plt.title('$y = sin(x)$');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRqLjzZXCYY6"
      },
      "source": [
        "Secondly, generate the noise that will be added to the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBSOG0GBCYY7"
      },
      "outputs": [],
      "source": [
        "noise = torch.randn(y_train.shape) / 10.\n",
        "\n",
        "plt.plot(x_train.numpy(), noise.numpy(), 'o')\n",
        "plt.axis([-10, 10, -1, 1])\n",
        "plt.title('Gaussian noise');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kos-FOSpCYY7"
      },
      "source": [
        "Lastly, add the noise to the clean data and get the spoiled data that we will use for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5s6RhVTICYY7"
      },
      "outputs": [],
      "source": [
        "y_train = y_train + noise\n",
        "plt.plot(x_train.numpy(), y_train.numpy(), 'o')\n",
        "plt.title('noisy sin(x)')\n",
        "plt.xlabel('x_train')\n",
        "plt.ylabel('y_train');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DH6vhddsCYY8"
      },
      "outputs": [],
      "source": [
        "x_train.unsqueeze_(1);\n",
        "y_train.unsqueeze_(1);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOggt3GECYY8"
      },
      "source": [
        "# Validation dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcZeNUn2CYY8"
      },
      "source": [
        "For validation we will use only clean equidistant data. Thus we will not generate noise for this set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8S5tejtqCYY8"
      },
      "outputs": [],
      "source": [
        "x_validation = torch.linspace(-10, 10, 100)\n",
        "y_validation = torch.sin(x_validation.data)\n",
        "plt.plot(x_validation.numpy(), y_validation.numpy(), 'o')\n",
        "plt.title('sin(x)')\n",
        "plt.xlabel('x_validation')\n",
        "plt.ylabel('y_validation');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLlliHCHCYY8"
      },
      "outputs": [],
      "source": [
        "x_validation.unsqueeze_(1)\n",
        "y_validation.unsqueeze_(1);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmEHBpLICYY9"
      },
      "source": [
        "# Model construction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lX_iCnbgCYY9"
      },
      "source": [
        "Fill out the class for 2-layer Feed Forward Neural Network with Sigmoid hidden layer.\n",
        "\n",
        "Class should consist of two methods:\n",
        "* `__init__` -- constructor, where the layers should be defined:\n",
        "    * Linear 1 -> n_hidden_neurons\n",
        "    * sigmoid activation\n",
        "    * Linear n_hidden_neurons -> 1\n",
        "* `forward` -- pass the signal through the network:\n",
        "    * x -> linear 1 -> sigmoid -> linear 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spbKpTQnCYY9"
      },
      "outputs": [],
      "source": [
        "class SineNet(torch.nn.Module):\n",
        "    def __init__(self, n_hidden_neurons):\n",
        "        super().__init__()\n",
        "        # YOUR CODE HERE\n",
        "        pass\n",
        "\n",
        "    def forward(self, x):\n",
        "        # YOUR CODE HERE\n",
        "        return x\n",
        "\n",
        "sine_net = SineNet(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTbyl64CCYY9"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXqFFIncCYY9"
      },
      "source": [
        "Here we will make prediction using our neural network. The main method here is `forward` that we have programmed within our `torch.Module` class.\n",
        "\n",
        "Below we will plot out predictions to understand how they are related to the validation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgZhOplkCYY9"
      },
      "outputs": [],
      "source": [
        "def predict(net, x, y):\n",
        "    y_pred = net.forward(x)\n",
        "\n",
        "    plt.plot(x.numpy(), y.numpy(), 'o', label='Groud truth')\n",
        "    plt.plot(x.numpy(), y_pred.data.numpy(), 'o', c='r', label='Prediction');\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.xlabel('$x$')\n",
        "    plt.ylabel('$y$')\n",
        "\n",
        "predict(sine_net, x_validation, y_validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ic_R_maCYY-"
      },
      "source": [
        "We see that the untrained neural network predict something, maybe even some dependency, but it is not related to the dependency that we want to reconstruct. \n",
        "\n",
        "Now let us train the network (tune the parameters to minimize the misfit between the labels and predictions)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvU-ri0aCYY-"
      },
      "source": [
        "# Loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG9Ie2MnCYY-"
      },
      "source": [
        "Now we will define the function using which we will measure the misfit.\n",
        "\n",
        "The requirements for this function are:\n",
        "* the lower the loss is the better the predictions are\n",
        "* slope should be non-zero for the majority of the locations\n",
        "\n",
        "In our case it will be mean squared error:\n",
        "$$\\frac{1}{N} \\sum_{i=1}^N \\left(Net(x_i) - t_i\\right)^2$$\n",
        "\n",
        "The lower this deviation is, the closer the prediction of the Neural Network to target.\n",
        "\n",
        "Code this loss function. Note that `pred` and `target` are the vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiagZ5bOCYY-"
      },
      "outputs": [],
      "source": [
        "def loss(pred, target):\n",
        "    ## YOUR CODE HERE\n",
        "    return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-0ZlNcVCYY-"
      },
      "source": [
        "# Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_zyW5WJCYY-"
      },
      "source": [
        "Now we have to tune the parameters minimising the loss function. Select `Adam` optimizer from `torch.optim`.\n",
        "\n",
        "As a first argument you should pass which parameters the optimizer should take care of. One can access whole set of parameters of `torch.Module` using `parameters()` method.\n",
        "\n",
        "Set `lr` (learning rate) to `1.0e-2`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lVSslYCCYY-"
      },
      "outputs": [],
      "source": [
        "## YOUR CODE HERE\n",
        "\n",
        "optimizer = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Td48izzKCYY-"
      },
      "source": [
        "# Training procedure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9rX5xd0CYY-"
      },
      "source": [
        "Now everything is ready for training.\n",
        "\n",
        "Compound the training cycle out of the following step:\n",
        "1. reset the gradients for trainable weights (`zero_grad()` method of the optimizer)\n",
        "2. forward signal propagation through the network (take vector of input signals `x_train` and call `forward` method of the `torch.nn.Module` with that `x_train` as an argument)\n",
        "3. loss value comutation (take`loss` that we have created above and comute misfit of prediction and target labels `y_train`)\n",
        "4. backpropagation through the network, computation of loss derivatives through every of the weights of the network (`backward` method of `torch.nn.Module`)\n",
        "5. optimizer step as all of the gradients for every of the weights are known (`step` method of the `Optimizer`)\n",
        "\n",
        "Repeat the steps above for some amount of times. Say, for `1000` and observe the change of the network predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W55m40LRCYY_"
      },
      "outputs": [],
      "source": [
        "for epoch_index in range(1000):\n",
        "    ## YOUR CODE HERE\n",
        "    pass    \n",
        "\n",
        "predict(sine_net, x_validation, y_validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAM5MVGfCYY_"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8NbBEdkCYY_"
      },
      "source": [
        "In this notebook we have covered all of the steps that the coder encounters while programming training procedure of a Neural Network.\n",
        "\n",
        "In serious projects every part of this process contatins tonns of code, but the philosophy everywhere is the same:\n",
        "\n",
        "* Get data\n",
        "* Define the Network\n",
        "* Define Loss\n",
        "* Select optimizer\n",
        "* Run training cycle"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9 | packaged by conda-forge | (main, Feb  2 2023, 20:26:08) [Clang 14.0.6 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "625a3e9bb539bddba3637b86871d7600e463f0e3e5553319a9ee64ea984715f3"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}